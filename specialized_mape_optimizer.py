#!/usr/bin/env python3
"""
ç‰¹å®šéŠ˜æŸ„ã‚¿ã‚¤ãƒ—ã§MAPE < 15%é”æˆã‚’ç›®æŒ‡ã™ç‰¹åŒ–äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
import logging

from data.stock_data import StockDataProvider

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SpecializedMAPEOptimizer:
    """ç‰¹å®šéŠ˜æŸ„ã‚¿ã‚¤ãƒ—ã§MAPE < 15%ã‚’ç›®æŒ‡ã™ç‰¹åŒ–ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.data_provider = StockDataProvider()

    def analyze_stock_characteristics(self, symbols: List[str]) -> Dict:
        """éŠ˜æŸ„ç‰¹æ€§ã®è©³ç´°åˆ†æ"""
        print("éŠ˜æŸ„ç‰¹æ€§åˆ†æä¸­...")

        stock_analysis = {}

        for symbol in symbols[:10]:
            try:
                data = self.data_provider.get_stock_data(symbol, "3mo")
                if len(data) < 30:
                    continue

                returns = data['Close'].pct_change().dropna()

                # ç‰¹æ€§åˆ†æ
                volatility = returns.std()
                mean_abs_return = returns.abs().mean()
                autocorr_1d = returns.autocorr(lag=1) if len(returns) > 1 else 0
                trend_consistency = self._calculate_trend_consistency(returns)
                predictability_score = self._calculate_predictability(returns)

                stock_analysis[symbol] = {
                    'volatility': volatility,
                    'mean_abs_return': mean_abs_return,
                    'autocorrelation': autocorr_1d,
                    'trend_consistency': trend_consistency,
                    'predictability_score': predictability_score,
                    'volume_consistency': self._calculate_volume_consistency(data),
                    'price_level': data['Close'].iloc[-1]
                }

            except Exception as e:
                logger.warning(f"Error analyzing {symbol}: {str(e)}")
                continue

        return stock_analysis

    def _calculate_trend_consistency(self, returns: pd.Series) -> float:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ä¸€è²«æ€§ã‚¹ã‚³ã‚¢"""
        if len(returns) < 10:
            return 0.0

        # 5æ—¥é–“ã®ç§»å‹•å¹³å‡ãƒˆãƒ¬ãƒ³ãƒ‰
        trend_signals = []
        for i in range(5, len(returns)):
            recent_trend = returns.iloc[i-5:i].mean()
            trend_signals.append(1 if recent_trend > 0 else -1)

        if len(trend_signals) < 2:
            return 0.0

        # ä¸€è²«æ€§ã‚’è¨ˆç®—ï¼ˆåŒã˜æ–¹å‘ãŒç¶šãæ¯”ç‡ï¼‰
        consistency = 0
        for i in range(1, len(trend_signals)):
            if trend_signals[i] == trend_signals[i-1]:
                consistency += 1

        return consistency / (len(trend_signals) - 1)

    def _calculate_predictability(self, returns: pd.Series) -> float:
        """äºˆæ¸¬å¯èƒ½æ€§ã‚¹ã‚³ã‚¢"""
        if len(returns) < 20:
            return 0.0

        # è¤‡æ•°ã®äºˆæ¸¬å¯èƒ½æ€§æŒ‡æ¨™
        scores = []

        # 1. è‡ªå·±ç›¸é–¢
        autocorr = abs(returns.autocorr(lag=1)) if len(returns) > 1 else 0
        scores.append(autocorr)

        # 2. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç¶™ç¶šæ€§
        momentum_consistency = 0
        for i in range(1, len(returns)):
            if returns.iloc[i] * returns.iloc[i-1] > 0:  # åŒã˜æ–¹å‘
                momentum_consistency += 1
        momentum_score = momentum_consistency / (len(returns) - 1)
        scores.append(momentum_score)

        # 3. å¹³å‡å›å¸°ãƒ‘ã‚¿ãƒ¼ãƒ³
        large_moves = returns[abs(returns) > returns.std()]
        if len(large_moves) > 1:
            reversal_rate = 0
            for i in range(1, len(large_moves)):
                if large_moves.iloc[i] * large_moves.iloc[i-1] < 0:  # åè»¢
                    reversal_rate += 1
            reversal_score = reversal_rate / (len(large_moves) - 1)
            scores.append(reversal_score)

        return np.mean(scores) if scores else 0.0

    def _calculate_volume_consistency(self, data: pd.DataFrame) -> float:
        """å‡ºæ¥é«˜ä¸€è²«æ€§ã‚¹ã‚³ã‚¢"""
        if 'Volume' not in data.columns or len(data) < 10:
            return 0.0

        volume_changes = data['Volume'].pct_change().dropna()
        volume_volatility = volume_changes.std()

        # ä½ã„å‡ºæ¥é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã»ã©ä¸€è²«æ€§ãŒé«˜ã„
        return 1.0 / (1.0 + volume_volatility) if volume_volatility > 0 else 1.0

    def categorize_stocks(self, stock_analysis: Dict) -> Dict:
        """éŠ˜æŸ„ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        categories = {
            'low_volatility_predictable': [],    # ä½ãƒœãƒ© + é«˜äºˆæ¸¬å¯èƒ½æ€§
            'trending_consistent': [],           # ãƒˆãƒ¬ãƒ³ãƒ‰ä¸€è²«æ€§ãŒé«˜ã„
            'mean_reverting': [],               # å¹³å‡å›å¸°æ€§ãŒå¼·ã„
            'high_autocorr': [],                # é«˜è‡ªå·±ç›¸é–¢
            'stable_volume': []                 # å®‰å®šå‡ºæ¥é«˜
        }

        for symbol, analysis in stock_analysis.items():
            vol = analysis['volatility']
            pred = analysis['predictability_score']
            trend = analysis['trend_consistency']
            autocorr = abs(analysis['autocorrelation'])
            vol_cons = analysis['volume_consistency']

            # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
            if vol < 0.02 and pred > 0.6:
                categories['low_volatility_predictable'].append(symbol)

            if trend > 0.7:
                categories['trending_consistent'].append(symbol)

            if pred > 0.7:  # å¹³å‡å›å¸°æˆåˆ†ãŒå¼·ã„
                categories['mean_reverting'].append(symbol)

            if autocorr > 0.3:
                categories['high_autocorr'].append(symbol)

            if vol_cons > 0.8:
                categories['stable_volume'].append(symbol)

        return categories

    def create_specialized_predictor(self, symbol: str, category: str) -> float:
        """ã‚«ãƒ†ã‚´ãƒªç‰¹åŒ–äºˆæ¸¬"""
        try:
            data = self.data_provider.get_stock_data(symbol, "1mo")
            if data.empty or len(data) < 10:
                return 0.0

            data = self.data_provider.calculate_technical_indicators(data)
            returns = data['Close'].pct_change().dropna()

            if len(returns) < 5:
                return 0.0

            # ã‚«ãƒ†ã‚´ãƒªåˆ¥ç‰¹åŒ–ãƒ­ã‚¸ãƒƒã‚¯
            if category == 'low_volatility_predictable':
                return self._predict_low_vol_stable(returns, data)
            elif category == 'trending_consistent':
                return self._predict_trending(returns, data)
            elif category == 'mean_reverting':
                return self._predict_mean_reverting(returns, data)
            elif category == 'high_autocorr':
                return self._predict_autocorr(returns, data)
            elif category == 'stable_volume':
                return self._predict_volume_stable(returns, data)
            else:
                return self._predict_default(returns, data)

        except Exception as e:
            logger.error(f"Error in specialized prediction for {symbol}: {str(e)}")
            return 0.0

    def _predict_low_vol_stable(self, returns: pd.Series, data: pd.DataFrame) -> float:
        """ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£å®‰å®šéŠ˜æŸ„ç”¨äºˆæ¸¬"""
        # è¶…ä¿å®ˆçš„äºˆæ¸¬ï¼ˆå°ã•ãªå‹•ãã‚’æ­£ç¢ºã«ï¼‰
        recent_trend = returns.iloc[-3:].mean()
        vol = returns.std()

        # æ¥µã‚ã¦å°ã•ãªäºˆæ¸¬
        prediction = recent_trend * 0.3
        max_prediction = vol * 0.5  # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®åŠåˆ†ã¾ã§

        return max(-max_prediction, min(max_prediction, prediction))

    def _predict_trending(self, returns: pd.Series, data: pd.DataFrame) -> float:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ä¸€è²«éŠ˜æŸ„ç”¨äºˆæ¸¬"""
        # ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šäºˆæ¸¬
        recent_trend = returns.iloc[-5:].mean()
        momentum = returns.iloc[-1]

        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«å¿œã˜ãŸäºˆæ¸¬
        if abs(recent_trend) > returns.std() * 0.5:
            prediction = recent_trend * 0.5 + momentum * 0.3
        else:
            prediction = momentum * 0.4

        # åˆ¶é™
        max_pred = returns.std() * 1.0
        return max(-max_pred, min(max_pred, prediction))

    def _predict_mean_reverting(self, returns: pd.Series, data: pd.DataFrame) -> float:
        """å¹³å‡å›å¸°éŠ˜æŸ„ç”¨äºˆæ¸¬"""
        # å¹³å‡å›å¸°äºˆæ¸¬
        recent_return = returns.iloc[-1]
        mean_return = returns.mean()
        vol = returns.std()

        # å¤§ããªå‹•ãã®å¾Œã¯åè»¢
        if abs(recent_return) > vol:
            prediction = -recent_return * 0.4 + mean_return * 0.2
        else:
            prediction = mean_return * 0.3

        # åˆ¶é™
        max_pred = vol * 0.8
        return max(-max_pred, min(max_pred, prediction))

    def _predict_autocorr(self, returns: pd.Series, data: pd.DataFrame) -> float:
        """é«˜è‡ªå·±ç›¸é–¢éŠ˜æŸ„ç”¨äºˆæ¸¬"""
        # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç¶™ç¶šäºˆæ¸¬
        momentum_1d = returns.iloc[-1]
        momentum_3d = returns.iloc[-3:].mean()

        # ç¶™ç¶šæ€§é‡è¦–
        prediction = momentum_1d * 0.4 + momentum_3d * 0.3

        # åˆ¶é™
        vol = returns.std()
        max_pred = vol * 0.7
        return max(-max_pred, min(max_pred, prediction))

    def _predict_volume_stable(self, returns: pd.Series, data: pd.DataFrame) -> float:
        """å®‰å®šå‡ºæ¥é«˜éŠ˜æŸ„ç”¨äºˆæ¸¬"""
        # å‡ºæ¥é«˜ã‚‚è€ƒæ…®ã—ãŸäºˆæ¸¬
        recent_return = returns.iloc[-1]

        if 'Volume' in data.columns:
            vol_ratio = data['Volume'].iloc[-1] / data['Volume'].rolling(10).mean().iloc[-1]
            volume_boost = 1.0 + (vol_ratio - 1.0) * 0.2  # å‡ºæ¥é«˜ã«ã‚ˆã‚‹èª¿æ•´
        else:
            volume_boost = 1.0

        prediction = recent_return * 0.3 * volume_boost

        # åˆ¶é™
        vol = returns.std()
        max_pred = vol * 0.6
        return max(-max_pred, min(max_pred, prediction))

    def _predict_default(self, returns: pd.Series, data: pd.DataFrame) -> float:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆäºˆæ¸¬"""
        return returns.iloc[-1] * 0.2

    def test_specialized_predictions(self, symbols: List[str]) -> Dict:
        """ç‰¹åŒ–äºˆæ¸¬ã®ãƒ†ã‚¹ãƒˆ"""
        print("\nç‰¹åŒ–äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)

        # éŠ˜æŸ„ç‰¹æ€§åˆ†æ
        stock_analysis = self.analyze_stock_characteristics(symbols)
        categories = self.categorize_stocks(stock_analysis)

        print(f"ã‚«ãƒ†ã‚´ãƒªåˆ†é¡çµæœ:")
        for category, stocks in categories.items():
            print(f"  {category}: {len(stocks)}éŠ˜æŸ„ {stocks}")

        # å„ã‚«ãƒ†ã‚´ãƒªã§ãƒ†ã‚¹ãƒˆ
        category_results = {}

        for category, stocks in categories.items():
            if not stocks:
                continue

            category_predictions = []
            category_actuals = []
            category_errors = []

            print(f"\n{category}ã‚«ãƒ†ã‚´ãƒªãƒ†ã‚¹ãƒˆ ({len(stocks)}éŠ˜æŸ„):")

            for symbol in stocks:
                try:
                    data = self.data_provider.get_stock_data(symbol, "2mo")
                    if len(data) < 20:
                        continue

                    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                    for i in range(10, 2, -1):
                        historical_data = data.iloc[:-i].copy()
                        if len(historical_data) < 10:
                            continue

                        # å®Ÿéš›ã®ãƒªã‚¿ãƒ¼ãƒ³
                        start_price = data.iloc[-i]['Close']
                        end_price = data.iloc[-i+1]['Close']
                        actual_return = (end_price - start_price) / start_price

                        # ç‰¹åŒ–äºˆæ¸¬
                        predicted_return = self._specialized_predict_with_data(
                            historical_data, symbol, category)

                        category_predictions.append(predicted_return)
                        category_actuals.append(actual_return)

                        # MAPEè¨ˆç®—ç”¨
                        if abs(actual_return) > 0.005:  # 0.5%ä»¥ä¸Šã®å‹•ã
                            mape_individual = abs((actual_return - predicted_return) / actual_return) * 100
                            category_errors.append(mape_individual)

                except Exception as e:
                    logger.warning(f"Error testing {symbol}: {str(e)}")
                    continue

            # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµæœ
            if category_errors:
                category_mape = np.mean(category_errors)
                category_mae = np.mean(np.abs(np.array(category_predictions) - np.array(category_actuals)))

                category_results[category] = {
                    'mape': category_mape,
                    'mae': category_mae,
                    'test_count': len(category_predictions),
                    'significant_count': len(category_errors)
                }

                print(f"  MAPE: {category_mape:.2f}%")
                print(f"  MAE: {category_mae:.4f}")
                print(f"  ãƒ†ã‚¹ãƒˆæ•°: {len(category_predictions)} (æœ‰åŠ¹MAPE: {len(category_errors)})")

        return category_results

    def _specialized_predict_with_data(self, data: pd.DataFrame, symbol: str, category: str) -> float:
        """éå»ãƒ‡ãƒ¼ã‚¿ã§ã®ç‰¹åŒ–äºˆæ¸¬"""
        try:
            data = self.data_provider.calculate_technical_indicators(data)
            returns = data['Close'].pct_change().dropna()

            if len(returns) < 3:
                return 0.0

            # ã‚«ãƒ†ã‚´ãƒªç‰¹åŒ–ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆç°¡ç•¥ç‰ˆï¼‰
            if category == 'low_volatility_predictable':
                return returns.iloc[-2:].mean() * 0.2
            elif category == 'trending_consistent':
                return returns.iloc[-3:].mean() * 0.4
            elif category == 'mean_reverting':
                return -returns.iloc[-1] * 0.3
            elif category == 'high_autocorr':
                return returns.iloc[-1] * 0.5
            elif category == 'stable_volume':
                return returns.iloc[-1] * 0.3
            else:
                return returns.iloc[-1] * 0.1

        except:
            return 0.0

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("ç‰¹å®šéŠ˜æŸ„ã‚¿ã‚¤ãƒ—ã§MAPE < 15%é”æˆãƒãƒ£ãƒ¬ãƒ³ã‚¸")
    print("=" * 60)

    data_provider = StockDataProvider()
    symbols = list(data_provider.jp_stock_codes.keys())

    optimizer = SpecializedMAPEOptimizer()

    # ç‰¹åŒ–äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
    results = optimizer.test_specialized_predictions(symbols)

    print(f"\n{'='*60}")
    print("ã‚«ãƒ†ã‚´ãƒªåˆ¥æœ€çµ‚çµæœ")
    print("=" * 60)

    best_category = None
    best_mape = float('inf')

    for category, metrics in results.items():
        print(f"{category}:")
        print(f"  MAPE: {metrics['mape']:.2f}%")
        print(f"  MAE: {metrics['mae']:.4f}")
        print(f"  ãƒ†ã‚¹ãƒˆæ•°: {metrics['test_count']}")

        if metrics['mape'] < best_mape:
            best_mape = metrics['mape']
            best_category = category

        if metrics['mape'] < 15:
            print("  âœ“ å®Ÿç”¨ãƒ¬ãƒ™ãƒ«é”æˆï¼")
        elif metrics['mape'] < 30:
            print("  â–³ å¤§å¹…æ”¹å–„")
        else:
            print("  ç¶™ç¶šæ”¹å–„ãŒå¿…è¦")
        print()

    if best_category:
        print(f"æœ€è‰¯çµæœ: {best_category} - MAPE {best_mape:.2f}%")
        if best_mape < 15:
            print("ğŸ‰ MAPE < 15% å®Ÿç”¨ãƒ¬ãƒ™ãƒ«é”æˆï¼")
        else:
            print(f"ç›®æ¨™ã¾ã§ {best_mape - 15:.1f}%ã®æ”¹å–„ãŒå¿…è¦")

if __name__ == "__main__":
    main()