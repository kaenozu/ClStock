#!/usr/bin/env python3
"""
ãƒã‚¤ãƒŠãƒªæ–¹å‘æ€§äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆä¸Šæ˜‡ãƒ»ä¸‹é™ã®ã¿ï¼‰
ã‚·ãƒ³ãƒ—ãƒ«ãª2ã‚¯ãƒ©ã‚¹åˆ†é¡ã§80%ä»¥ä¸Šã®ç²¾åº¦ã‚’ç›®æŒ‡ã™
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
import logging
from utils.logger_config import setup_logger
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score, classification_report
import warnings

warnings.filterwarnings("ignore")

from data.stock_data import StockDataProvider

# ãƒ­ã‚°è¨­å®š
logger = setup_logger(__name__)


class BinaryDirectionPredictor:
    """ãƒã‚¤ãƒŠãƒªæ–¹å‘æ€§äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.data_provider = StockDataProvider()
        self.scaler = StandardScaler()

    def create_focused_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """æ–¹å‘æ€§äºˆæ¸¬ã«é›†ä¸­ã—ãŸç‰¹å¾´é‡ï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰"""
        features = pd.DataFrame(index=data.index)

        close = data["Close"]
        volume = data["Volume"]

        # 1. æœ€ã‚‚é‡è¦ãªç§»å‹•å¹³å‡é–¢ä¿‚
        sma_5 = close.rolling(5).mean()
        sma_20 = close.rolling(20).mean()
        sma_50 = close.rolling(50).mean()

        # ç§»å‹•å¹³å‡ãƒˆãƒ¬ãƒ³ãƒ‰
        features["trend_short"] = (sma_5 > sma_20).astype(int)
        features["trend_medium"] = (sma_20 > sma_50).astype(int)
        features["trend_alignment"] = ((sma_5 > sma_20) & (sma_20 > sma_50)).astype(int)

        # ä¾¡æ ¼ã¨ç§»å‹•å¹³å‡ã®é–¢ä¿‚
        features["price_above_sma20"] = (close > sma_20).astype(int)
        features["price_above_sma50"] = (close > sma_50).astype(int)

        # ç§»å‹•å¹³å‡ã®å‚¾ã
        features["sma20_rising"] = (sma_20 > sma_20.shift(5)).astype(int)
        features["sma50_rising"] = (sma_50 > sma_50.shift(10)).astype(int)

        # 2. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼ˆæœ€é‡è¦ï¼‰
        returns = close.pct_change()

        # æœ€è¿‘ã®å‹•å‘
        features["recent_positive"] = (returns.rolling(3).sum() > 0).astype(int)
        features["momentum_1w"] = (close > close.shift(5)).astype(int)
        features["momentum_2w"] = (close > close.shift(10)).astype(int)

        # 3. RSIï¼ˆç°¡ç•¥ç‰ˆï¼‰
        rsi = self._calculate_rsi(close, 14)
        features["rsi_bullish"] = (rsi > 50).astype(int)
        features["rsi_strong_bull"] = (rsi > 60).astype(int)
        features["rsi_oversold"] = (rsi < 30).astype(int)

        # 4. ãƒœãƒªãƒ¥ãƒ¼ãƒ ç¢ºèª
        vol_avg = volume.rolling(20).mean()
        features["volume_above_avg"] = (volume > vol_avg).astype(int)
        features["strong_volume"] = (volume > vol_avg * 1.5).astype(int)

        # 5. ä¾¡æ ¼ä½ç½®
        high_20 = data["High"].rolling(20).max()
        low_20 = data["Low"].rolling(20).min()
        price_position = (close - low_20) / (high_20 - low_20)
        features["price_upper_half"] = (price_position > 0.5).astype(int)
        features["price_top_quarter"] = (price_position > 0.75).astype(int)

        return features

    def _calculate_rsi(self, prices: pd.Series, window: int = 14) -> pd.Series:
        """RSIè¨ˆç®—"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))

    def create_binary_target(
        self, data: pd.DataFrame, prediction_days: int = 5
    ) -> pd.Series:
        """ãƒã‚¤ãƒŠãƒªã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆä¸Šæ˜‡=1, ä¸‹é™=0ï¼‰"""
        close = data["Close"]

        # å°†æ¥ãƒªã‚¿ãƒ¼ãƒ³
        future_return = close.shift(-prediction_days).pct_change(prediction_days)

        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒã‚¤ãƒŠãƒªåˆ†é¡
        target = (future_return > 0).astype(int)

        return target

    def filter_significant_periods(
        self, features: pd.DataFrame, target: pd.Series, data: pd.DataFrame
    ) -> Tuple[pd.DataFrame, pd.Series]:
        """æœ‰æ„ãªæœŸé–“ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        close = data["Close"]
        returns = close.pct_change()

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆå®‰å®šæœŸé–“ã®ã¿ï¼‰
        vol_20 = returns.rolling(20).std()
        stable_periods = vol_20 < vol_20.quantile(0.7)

        # ãƒˆãƒ¬ãƒ³ãƒ‰æœŸé–“ã®ã¿ï¼ˆæ¨ªã°ã„ã‚’é™¤å¤–ï¼‰
        sma_20 = close.rolling(20).mean()
        trend_strength = abs(sma_20.pct_change(10))
        trending_periods = trend_strength > 0.02  # 2%ä»¥ä¸Šã®å¤‰åŒ–

        # çµ„ã¿åˆã‚ã›
        valid_periods = stable_periods & trending_periods

        return features[valid_periods], target[valid_periods]

    def train_binary_classifier(
        self, X: pd.DataFrame, y: pd.Series
    ) -> Tuple[Dict, Dict]:
        """ãƒã‚¤ãƒŠãƒªåˆ†é¡å™¨ã®è¨“ç·´"""

        models = {
            "random_forest": RandomForestClassifier(
                n_estimators=100,
                max_depth=8,
                min_samples_split=10,
                min_samples_leaf=5,
                random_state=42,
                class_weight="balanced",
            ),
            "gradient_boosting": GradientBoostingClassifier(
                n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42
            ),
            "logistic": LogisticRegression(
                random_state=42, max_iter=200, class_weight="balanced"
            ),
        }

        # æ™‚ç³»åˆ—åˆ†å‰²
        tscv = TimeSeriesSplit(n_splits=3)
        model_scores = {}
        trained_models = {}

        for name, model in models.items():
            accuracies = []

            for train_idx, val_idx in tscv.split(X):
                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

                # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
                X_train_scaled = self.scaler.fit_transform(X_train)
                X_val_scaled = self.scaler.transform(X_val)

                # è¨“ç·´
                model.fit(X_train_scaled, y_train)

                # äºˆæ¸¬
                y_pred = model.predict(X_val_scaled)

                # ç²¾åº¦
                accuracy = accuracy_score(y_val, y_pred)
                accuracies.append(accuracy)

            avg_accuracy = np.mean(accuracies)
            model_scores[name] = {"accuracy": avg_accuracy, "std": np.std(accuracies)}

            print(f"  {name}: {avg_accuracy:.3f} Â± {np.std(accuracies):.3f}")

            # å…¨ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è¨“ç·´
            X_scaled = self.scaler.fit_transform(X)
            model.fit(X_scaled, y)
            trained_models[name] = model

        return model_scores, trained_models

    def test_binary_system(self, symbols: List[str]) -> Dict:
        """ãƒã‚¤ãƒŠãƒªæ–¹å‘æ€§äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
        print("ãƒã‚¤ãƒŠãƒªæ–¹å‘æ€§äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆ80%ç›®æ¨™ï¼‰")
        print("=" * 60)

        all_results = []

        for symbol in symbols[:15]:
            try:
                print(f"\nå‡¦ç†ä¸­: {symbol}")

                # ãƒ‡ãƒ¼ã‚¿å–å¾—
                data = self.data_provider.get_stock_data(symbol, "2y")
                if len(data) < 200:
                    continue

                # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
                features = self.create_focused_features(data)
                target = self.create_binary_target(data, prediction_days=5)

                # æœ‰æ„æœŸé–“ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                X_filtered, y_filtered = self.filter_significant_periods(
                    features, target, data
                )

                # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                valid_idx = ~(X_filtered.isna().any(axis=1) | y_filtered.isna())
                X = X_filtered[valid_idx].fillna(0)
                y = y_filtered[valid_idx]

                if len(X) < 50:
                    print(f"  ã‚¹ã‚­ãƒƒãƒ—: æœ‰æ„ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³ ({len(X)})")
                    continue

                print(f"  æœ‰æ„ã‚µãƒ³ãƒ—ãƒ«: {len(X)}")

                # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ
                class_counts = y.value_counts()
                print(f"  ä¸Šæ˜‡/ä¸‹é™: {class_counts.get(1, 0)}/{class_counts.get(0, 0)}")

                # ãƒãƒ©ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆä¿®æ­£ç‰ˆï¼‰
                class_values = list(class_counts.values)
                minority_ratio = min(class_values) / sum(class_values)
                if minority_ratio < 0.3:
                    print(
                        f"  ã‚¹ã‚­ãƒƒãƒ—: ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ (å°‘æ•°ã‚¯ãƒ©ã‚¹: {minority_ratio:.1%})"
                    )
                    continue

                # åˆ†å‰²
                split_idx = int(len(X) * 0.7)
                X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
                y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

                if len(X_test) < 15:
                    continue

                # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
                model_scores, trained_models = self.train_binary_classifier(
                    X_train, y_train
                )

                # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«é¸æŠ
                best_model_name = max(
                    model_scores.keys(), key=lambda x: model_scores[x]["accuracy"]
                )
                best_model = trained_models[best_model_name]

                # ãƒ†ã‚¹ãƒˆäºˆæ¸¬
                X_test_scaled = self.scaler.transform(X_test)
                test_predictions = best_model.predict(X_test_scaled)

                # ãƒ†ã‚¹ãƒˆç²¾åº¦
                test_accuracy = accuracy_score(y_test, test_predictions)

                result = {
                    "symbol": symbol,
                    "accuracy": test_accuracy,
                    "best_model": best_model_name,
                    "test_samples": len(X_test),
                    "train_accuracy": model_scores[best_model_name]["accuracy"],
                    "class_balance": minority_ratio,
                }

                all_results.append(result)

                print(f"  ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«: {best_model_name}")
                print(f"  ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy:.1%}")

                if test_accuracy >= 0.8:
                    print("  âœ“ 80%é”æˆï¼")
                elif test_accuracy >= 0.75:
                    print("  â–³ 75%ä»¥ä¸Š")
                elif test_accuracy >= 0.7:
                    print("  â—‹ 70%ä»¥ä¸Š")

            except Exception as e:
                print(f"  ã‚¨ãƒ©ãƒ¼: {str(e)}")
                continue

        return self._analyze_binary_results(all_results)

    def _analyze_binary_results(self, results: List[Dict]) -> Dict:
        """ãƒã‚¤ãƒŠãƒªäºˆæ¸¬çµæœã®åˆ†æ"""
        if not results:
            return {"error": "No results"}

        accuracies = [r["accuracy"] for r in results]

        max_accuracy = np.max(accuracies)
        avg_accuracy = np.mean(accuracies)
        median_accuracy = np.median(accuracies)

        # ç²¾åº¦åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
        excellent_count = sum(1 for acc in accuracies if acc >= 0.8)
        good_count = sum(1 for acc in accuracies if acc >= 0.75)
        decent_count = sum(1 for acc in accuracies if acc >= 0.7)

        print(f"\n" + "=" * 60)
        print("ãƒã‚¤ãƒŠãƒªæ–¹å‘æ€§äºˆæ¸¬çµæœ")
        print("=" * 60)
        print(f"ãƒ†ã‚¹ãƒˆéŠ˜æŸ„æ•°: {len(results)}")
        print(f"æœ€é«˜ç²¾åº¦: {max_accuracy:.1%}")
        print(f"å¹³å‡ç²¾åº¦: {avg_accuracy:.1%}")
        print(f"ä¸­å¤®å€¤ç²¾åº¦: {median_accuracy:.1%}")
        print(f"80%ä»¥ä¸Š: {excellent_count}/{len(results)} éŠ˜æŸ„")
        print(f"75%ä»¥ä¸Š: {good_count}/{len(results)} éŠ˜æŸ„")
        print(f"70%ä»¥ä¸Š: {decent_count}/{len(results)} éŠ˜æŸ„")

        # ãƒˆãƒƒãƒ—3çµæœ
        top_results = sorted(results, key=lambda x: x["accuracy"], reverse=True)[:3]
        print(f"\nãƒˆãƒƒãƒ—3çµæœ:")
        for i, result in enumerate(top_results, 1):
            print(
                f"  {i}. {result['symbol']}: {result['accuracy']:.1%} ({result['best_model']})"
            )

        if max_accuracy >= 0.8:
            print(f"\nğŸ‰ 80%ä»¥ä¸Šé”æˆï¼æœ€é«˜ {max_accuracy:.1%}")
        elif avg_accuracy >= 0.75:
            print(f"\nâ–³ è‰¯å¥½ï¼šå¹³å‡ {avg_accuracy:.1%}")
        elif max_accuracy >= 0.75:
            print(f"\nâ–³ éƒ¨åˆ†çš„æˆåŠŸï¼šæœ€é«˜ {max_accuracy:.1%}")

        return {
            "max_accuracy": max_accuracy,
            "avg_accuracy": avg_accuracy,
            "excellent_count": excellent_count,
            "results": results,
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ãƒã‚¤ãƒŠãƒªæ–¹å‘æ€§äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆã‚·ãƒ³ãƒ—ãƒ«2ã‚¯ãƒ©ã‚¹ï¼‰")
    print("=" * 60)

    data_provider = StockDataProvider()
    symbols = list(data_provider.jp_stock_codes.keys())

    predictor = BinaryDirectionPredictor()
    results = predictor.test_binary_system(symbols)

    if "error" not in results:
        if results["max_accuracy"] >= 0.8:
            print(f"âœ“ ç›®æ¨™é”æˆï¼æœ€é«˜ç²¾åº¦ {results['max_accuracy']:.1%}")
        else:
            print(f"ç¶™ç¶šæ”¹å–„ä¸­ï¼šç¾åœ¨ {results['max_accuracy']:.1%}")


if __name__ == "__main__":
    main()
